{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2542c710",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sdss5_target_flags']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "from matplotlib.pyplot import figure\n",
    "from astropy.io import fits\n",
    "from astropy.table import Table\n",
    "\n",
    "from astropy.coordinates import SkyCoord\n",
    "from astropy import units as u\n",
    "from astropy.table import QTable\n",
    "\n",
    "filename_path = '../data/astraAllStarASPCAP-0.7.fits'\n",
    "\n",
    "# this function is Lucy's way to get rid of columns that are more than 1D (pandas doesn't support that)\n",
    "def Table_to_pandas(fn):\n",
    "    data = fits.open(fn)\n",
    "    df = QTable(data[2].data)\n",
    "    cols = []\n",
    "    cols_drop = []\n",
    "    for i in df.columns:\n",
    "        if np.size(df[i][0])==1:\n",
    "            cols.append(i)\n",
    "        else:\n",
    "            cols_drop.append(i)\n",
    "    print(cols_drop)\n",
    "    return df[cols].to_pandas()\n",
    "\n",
    "df_sdss5 = Table_to_pandas(filename_path)\n",
    "\n",
    "df_sdss5 = df_sdss5[(df_sdss5['teff']>4500) & (df_sdss5['teff']<6500)]\n",
    "df_sdss5 = df_sdss5[(df_sdss5['snr']>=200)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8a3066c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# 1. SDSS cut on Fe/H error\n",
    "# -------------------------------\n",
    "df_sdss5 = df_sdss5[df_sdss5['gaia_dr3_source_id'] > 0]\n",
    "df_sdss_metcut = df_sdss5[(df_sdss5['e_fe_h'] < 0.1) & (df_sdss5['e_mg_h'] < 0.1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "778a20a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure unique SDSS rows per Gaia source\n",
    "df_sdss_metcut = df_sdss_metcut.sort_values(['snr'], ascending=False)\n",
    "df_sdss_metcut = df_sdss_metcut.drop_duplicates(subset='gaia_dr3_source_id', keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42b76a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# 2. Save Gaia IDs from SDSS cut\n",
    "# -------------------------------\n",
    "df_sdss_metcut['gaia_dr3_source_id'].to_csv('../data/gaia_ids_from_sdss.txt', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb257940",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# 3. Gaia RVS flags / high SNR selection\n",
    "# -------------------------------\n",
    "df_gaia_rvs_flags = pd.read_csv(\"../data/gaia_rvs_flags.csv\")\n",
    "\n",
    "# Keep only sources with RV spectra\n",
    "df_gaia_has_rvs = df_gaia_rvs_flags[df_gaia_rvs_flags['has_rvs'] == True]\n",
    "\n",
    "# High SNR spectra\n",
    "df_gaia_high_snr = df_gaia_has_rvs[df_gaia_has_rvs['rvs_spec_sig_to_noise'] > 100]\n",
    "\n",
    "# Optional: save high SNR source_ids to VOTable, to upload to gaia archive and get their spectra\n",
    "t = Table()\n",
    "t['source_id'] = df_gaia_high_snr['source_id'].values\n",
    "t.write('../data/gaia_high_snr_source_ids_revised.vot', format='votable', overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f6223de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lambda values are based on GAIA documentation\n",
    "# Load the downloaded spectra into a dataframe called rvs_spectra_df\n",
    "# Plot an example \n",
    "\n",
    "lambdas = np.linspace(846, 870, 2401)\n",
    "\n",
    "t = Table.read(\"../data/rvs_1.xml\", format=\"votable\")\n",
    "\n",
    "rvs_spectra_df = t.to_pandas()\n",
    "\n",
    "rvs_spectra_df['source_id'] = rvs_spectra_df['datalinkID']\n",
    "rvs_spectra_df = rvs_spectra_df[['source_id', 'flux', 'flux_error']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1de1827",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2894\n"
     ]
    }
   ],
   "source": [
    "# Keep spectra who are in sdss_metcut\n",
    "\n",
    "stars_spectra = rvs_spectra_df[rvs_spectra_df['source_id'].isin(df_sdss_metcut['gaia_dr3_source_id'])]\n",
    "print(len(stars_spectra))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "df076acd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2842"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop duplicates. By looking at a few examples, seemed like duplicates have the exact same spectra. so I just keep first.\n",
    "# But maybe there is a better way?\n",
    "\n",
    "stars_spectra = stars_spectra.drop_duplicates(subset='source_id', keep='first')\n",
    "len(stars_spectra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d5531cbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2842\n"
     ]
    }
   ],
   "source": [
    "# Keep stars from sdss_metcut who are in the spectra\n",
    "\n",
    "stars_labels = df_sdss_metcut[df_sdss_metcut['gaia_dr3_source_id'].isin(stars_spectra['source_id'])]\n",
    "print(len(stars_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7716d369",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/g0/fl404sj151l2v9xcdkjz9fq80000gn/T/ipykernel_11077/13363840.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  stars_labels['source_id'] = stars_labels['gaia_dr3_source_id']\n"
     ]
    }
   ],
   "source": [
    "stars_labels['source_id'] = stars_labels['gaia_dr3_source_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3b594b5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Gaia elements in most reliable + reliable giants: ***\n",
      "['n_h', 'mg_h', 'si_h', 'fe_h', 'ni_h', 'ca_h', 'ce_h']\n",
      "*** Gaia elements in most reliable + reliable dwarfs: ***\n",
      "['mg_h', 'si_h', 'fe_h', 'ni_h', 'ca_h']\n"
     ]
    }
   ],
   "source": [
    "# For giants and dwarfs\n",
    "most_reliable_giants = ['c_h', 'n_h', 'o_h', 'mg_h', 'al_h', 'si_h', 'mn_h', 'fe_h', 'ni_h']\n",
    "reliable_giants = ['na_h', 'k_h', 'ca_h', 'co_h', 'ce_h']\n",
    "most_reliable_dwarfs = ['c_h', 'mg_h', 'si_h', 'fe_h', 'ni_h']\n",
    "reliable_dwarfs = ['o_h', 'al_h', 'k_h', 'ca_h', 'mn_h']\n",
    "\n",
    "gaia_elements = ['n_h', 'mg_h', 'si_h', 's_h', 'ca_h', 'ti_h', 'cr_h', 'fe_h', 'ni_h', 'ce_h', 'nd_h']\n",
    "\n",
    "giant_elements = [] #most_reliable + reliable\n",
    "dwarf_elements = [] #most_reliable + reliable\n",
    "\n",
    "print(\"*** Gaia elements in most reliable + reliable giants: ***\")\n",
    "for i in range(len(most_reliable_giants)):\n",
    "    if most_reliable_giants[i] in gaia_elements:\n",
    "        giant_elements.append(most_reliable_giants[i])\n",
    "\n",
    "for i in range(len(reliable_giants)):\n",
    "    if reliable_giants[i] in gaia_elements:\n",
    "        giant_elements.append(reliable_giants[i])\n",
    "\n",
    "print(giant_elements)\n",
    "\n",
    "print(\"*** Gaia elements in most reliable + reliable dwarfs: ***\")\n",
    "for i in range(len(most_reliable_dwarfs)):\n",
    "    if most_reliable_dwarfs[i] in gaia_elements:\n",
    "        dwarf_elements.append(most_reliable_dwarfs[i])\n",
    "\n",
    "for i in range(len(reliable_dwarfs)):\n",
    "    if reliable_dwarfs[i] in gaia_elements:\n",
    "        dwarf_elements.append(reliable_dwarfs[i])\n",
    "    \n",
    "print(dwarf_elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a42283a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of giants =  1667\n",
      "['source_id', 'teff', 'e_teff', 'logg', 'e_logg', 'n_h', 'e_n_h', 'mg_h', 'e_mg_h', 'si_h', 'e_si_h', 'fe_h', 'e_fe_h', 'ni_h', 'e_ni_h', 'ca_h', 'e_ca_h', 'ce_h', 'e_ce_h']\n"
     ]
    }
   ],
   "source": [
    "giants_label_names = ['source_id', 'teff', 'e_teff', 'logg', 'e_logg']\n",
    "giants_label_names += [\n",
    "    col\n",
    "    for el in giant_elements\n",
    "    for col in (el, f\"e_{el}\")\n",
    "]\n",
    "giant_labels = stars_labels[giants_label_names]\n",
    "giants_df = stars_spectra.merge(giant_labels, on='source_id', how='inner')\n",
    "giants_df = giants_df[(giants_df['logg'] > 1.5) & (giants_df['logg'] < 3.5)]\n",
    "giants_df = giants_df[giants_df['e_fe_h'] < 0.1]\n",
    "giants_df = giants_df[giants_df['e_mg_h'] < 0.1]\n",
    "giants_df = giants_df[giants_df['e_si_h'] < 0.1]\n",
    "giants_df = giants_df[giants_df['e_ni_h'] < 0.1]\n",
    "giants_df = giants_df[giants_df['e_ca_h'] < 0.1]\n",
    "giants_df = giants_df[giants_df['e_ce_h'] < 0.1]\n",
    "print(\"number of giants = \", len(giants_df))\n",
    "print(giants_label_names)\n",
    "\n",
    "for p in ['teff', 'logg', 'n_h', 'mg_h', 'si_h', 'fe_h', 'ni_h', 'ca_h', 'ce_h']:\n",
    "    err_col = f\"e_{p}\"\n",
    "    # Boolean mask of missing values (NaN)\n",
    "    mask = giants_df[p].isna() | giants_df[p].astype(str).isin(['--', 'masked', '<Masked>']) | giants_df[err_col].isna() | giants_df[err_col].astype(str).isin(['--', 'masked', '<Masked>'])\n",
    "    stars_masked = giants_df[~mask]\n",
    "    med = np.median(stars_masked[p])\n",
    "    giants_df.loc[mask, p] = med\n",
    "    giants_df.loc[mask, err_col] = 9999\n",
    "\n",
    "giants_df.to_pickle('../data/giants_rel_most_rel.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ee4e7cf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of dwarfs =  1149\n",
      "['source_id', 'teff', 'e_teff', 'logg', 'e_logg', 'mg_h', 'e_mg_h', 'si_h', 'e_si_h', 'fe_h', 'e_fe_h', 'ni_h', 'e_ni_h', 'ca_h', 'e_ca_h']\n"
     ]
    }
   ],
   "source": [
    "dwarfs_label_names = ['source_id', 'teff', 'e_teff', 'logg', 'e_logg']\n",
    "dwarfs_label_names += [\n",
    "    col\n",
    "    for el in dwarf_elements\n",
    "    for col in (el, f\"e_{el}\")\n",
    "]\n",
    "dwarf_labels = stars_labels[dwarfs_label_names]\n",
    "dwarfs_df = stars_spectra.merge(dwarf_labels, on='source_id', how='inner')\n",
    "dwarfs_df = dwarfs_df[(dwarfs_df['logg'] > 3.5)]\n",
    "dwarfs_df = dwarfs_df[dwarfs_df['e_fe_h'] < 0.1]\n",
    "dwarfs_df = dwarfs_df[dwarfs_df['e_mg_h'] < 0.1]\n",
    "dwarfs_df = dwarfs_df[dwarfs_df['e_si_h'] < 0.1]\n",
    "dwarfs_df = dwarfs_df[dwarfs_df['e_ni_h'] < 0.1]\n",
    "dwarfs_df = dwarfs_df[dwarfs_df['e_ca_h'] < 0.1]\n",
    "\n",
    "print(\"number of dwarfs = \", len(dwarfs_df))\n",
    "print(dwarfs_label_names)\n",
    "\n",
    "for p in ['teff', 'logg', 'mg_h', 'si_h', 'fe_h', 'ni_h', 'ca_h']:\n",
    "    err_col = f\"e_{p}\"\n",
    "    # Boolean mask of missing values (NaN)\n",
    "    mask = dwarfs_df[p].isna() | dwarfs_df[p].astype(str).isin(['--', 'masked', '<Masked>']) | dwarfs_df[err_col].isna() | dwarfs_df[err_col].astype(str).isin(['--', 'masked', '<Masked>'])\n",
    "    stars_masked = dwarfs_df[~mask]\n",
    "    med = np.median(stars_masked[p])\n",
    "    dwarfs_df.loc[mask, p] = med\n",
    "    dwarfs_df.loc[mask, err_col] = 9999\n",
    "\n",
    "dwarfs_df.to_pickle('../data/dwarfs_rel_most_rel.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab99efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For a general example\n",
    "tutorial_labels = ['source_id', 'teff', 'e_teff', 'logg', 'e_logg', 'fe_h', 'e_fe_h','o_h', 'e_o_h', 'mg_h', 'e_mg_h', 'si_h', 'e_si_h']\n",
    "stars_labels = stars_labels[tutorial_labels]\n",
    "\n",
    "stars_df = stars_spectra.merge(stars_labels, on='source_id', how='inner')\n",
    "print(len(stars_df))\n",
    "\n",
    "params = ['teff', 'logg', 'fe_h', 'o_h', 'mg_h', 'si_h']\n",
    "\n",
    "for p in params:\n",
    "    err_col = f\"e_{p}\"\n",
    "    # Boolean mask of missing values (NaN)\n",
    "    mask = stars_df[p].isna() | stars_df[p].astype(str).isin(['--', 'masked', '<Masked>']) | stars_df[err_col].isna() | stars_df[err_col].astype(str).isin(['--', 'masked', '<Masked>'])\n",
    "    stars_masked = stars_df[~mask]\n",
    "    med = np.median(stars_masked[p])\n",
    "    stars_df.loc[mask, p] = med\n",
    "    stars_df.loc[mask, err_col] = 9999\n",
    "\n",
    "stars_df.to_pickle('../data/stars_feb4.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "haniyeh_research",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
